{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63437823-3d21-4ce8-9e83-af50e9088d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923fed86-84c2-4fb8-a516-7e551df0b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = \"/reef/sqt2/SINGLE_UTT/cmv/roberta-base\"\n",
    "all_seeds = os.listdir(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544294c0-f1e8-4c11-a144-9d538440fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = {}\n",
    "for seed in all_seeds:\n",
    "    try:\n",
    "        pred_path = os.path.join(saved_path, seed, \"predictions.csv\")\n",
    "        pred_file = open(pred_path, 'r')\n",
    "        pred_lines = pred_file.readlines()[1:]\n",
    "        # print(pred_lines[0])\n",
    "        for line in pred_lines:\n",
    "            id2pred = line.split(\",\")\n",
    "            \n",
    "            assert len(id2pred) == 3\n",
    "            utt_id = id2pred[0]\n",
    "            utt_pred = id2pred[1]\n",
    "            if utt_id not in all_predictions:\n",
    "                all_predictions[utt_id] = int(utt_pred)\n",
    "            else:\n",
    "                all_predictions[utt_id] += int(utt_pred)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7635257-0405-43d7-a2f9-cd84b774d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/sqt2/.convokit/downloads/conversations-gone-awry-cmv-corpus\n"
     ]
    }
   ],
   "source": [
    "from convokit import download, Corpus\n",
    "corpus = Corpus(filename=download(\"conversations-gone-awry-cmv-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec5da90-a932-46fa-828f-1cb6903795ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 363, 4: 49, 0: 419, 8: 73, 9: 91, 2: 65, 1: 100, 3: 58, 7: 56, 5: 41, 6: 53}\n",
      "243 284\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "agreement_spectrum = {}\n",
    "true_agreement = 0\n",
    "num_convo = 0\n",
    "hard_att = 0\n",
    "hard_non = 0\n",
    "hard_samples = []\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == 'test':\n",
    "        num_convo += 1\n",
    "        max_agreement = 0\n",
    "        # print(convo)\n",
    "        for utterance in convo.iter_utterances():\n",
    "            id = utterance.id\n",
    "            if id in all_predictions:\n",
    "                if all_predictions[id] > max_agreement:\n",
    "                    max_agreement = all_predictions[id]\n",
    "        # Hard attack\n",
    "        if convo.meta['has_removed_comment'] == False:\n",
    "            if max_agreement >= 4:\n",
    "                hard_non += 1\n",
    "                hard_samples.append(convo.id)\n",
    "        else:\n",
    "            if max_agreement <= 6:\n",
    "                hard_att += 1\n",
    "                hard_samples.append(convo.id)\n",
    "        \n",
    "        # if max_agreement >= 8 and convo.meta['conversation_has_personal_attack'] == False:\n",
    "        #     hard_non += 1\n",
    "        #     hard_samples.append(convo.id)\n",
    "        # if max_agreement <= 3 and convo.meta['conversation_has_personal_attack'] == True:\n",
    "        #     hard_att += 1\n",
    "        #     hard_samples.append(convo.id)\n",
    "        # Hard non-attack\n",
    "        \n",
    "        if max_agreement ==10 and convo.meta['has_removed_comment'] == True:\n",
    "            true_agreement += 1\n",
    "        if max_agreement not in agreement_spectrum:\n",
    "            agreement_spectrum[max_agreement] = 1\n",
    "        else:\n",
    "            agreement_spectrum[max_agreement] += 1\n",
    "print(agreement_spectrum)\n",
    "print(hard_non, hard_att)\n",
    "print(true_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8ed7f2-bf44-4324-9621-73afd7aebf54",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conversation_has_personal_attack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m convo \u001b[38;5;129;01min\u001b[39;00m corpus\u001b[38;5;241m.\u001b[39miter_conversations():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convo\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mconvo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconversation_has_personal_attack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m utterance \u001b[38;5;129;01min\u001b[39;00m convo\u001b[38;5;241m.\u001b[39miter_utterances():\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m utterance\u001b[38;5;241m.\u001b[39mid\n",
      "File \u001b[0;32m/reef/conda-envs/jacq-zissou-env-3.11/lib/python3.11/site-packages/convokit/model/convoKitMeta.py:37\u001b[0m, in \u001b[0;36mConvoKitMeta.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# in DB mode, metadata field mutation would not be updated. (ex. mutating dict/list metadata fields)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# we align MEM mode behavior and DB mode by making deepcopy of metadata fields, so mutation no longer\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# affect corpus metadata backend, but only acting on the copy of it.\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     immutable_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, immutable_types):\n",
      "File \u001b[0;32m/reef/conda-envs/jacq-zissou-env-3.11/lib/python3.11/site-packages/convokit/model/backendMapper.py:179\u001b[0m, in \u001b[0;36mMemMapper.get_data\u001b[0;34m(self, component_type, component_id, property_name, index)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collection[component_id]\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollection\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomponent_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conversation_has_personal_attack'"
     ]
    }
   ],
   "source": [
    "for derail_id in all_predictions:\n",
    "    if all_predictions[derail_id] == 10:\n",
    "        for convo in corpus.iter_conversations():\n",
    "            if convo.meta['split'] == 'test':\n",
    "                if convo.meta['has_removed_comment'] == False:\n",
    "                    for utterance in convo.iter_utterances():\n",
    "                        id = utterance.id\n",
    "                        # if id == derail_id:\n",
    "                            # print(utterance.text)\n",
    "                            #print next utterance here\n",
    "                            # print()\n",
    "                            # print()\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd833c-91ac-403b-bdd0-23b28ab588a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = \"/reef/sqt2/BERTCRAFT/cmv/roberta-base/seed-1/predictions.csv\"\n",
    "pred_file = open(pred_path, 'r')\n",
    "pred_lines = pred_file.readlines()[1:]\n",
    "pred_dict = {}\n",
    "for line in pred_lines:\n",
    "    id2pred = line.split(\",\")\n",
    "    \n",
    "    assert len(id2pred) == 3\n",
    "    utt_id = id2pred[0]\n",
    "    utt_pred = id2pred[1]\n",
    "    pred_dict[utt_id] = int(utt_pred)\n",
    "print(len(pred_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b045c9-93c9-4a56-a7ca-5cb5a12340e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = \"cmv\"\n",
    "label_metadata = \"conversation_has_personal_attack\" if corpus_name == \"wikiconv\" else \"has_removed_comment\"\n",
    "utt_label_metadata = \"comment_has_personal_attack\" if corpus_name == \"wikiconv\" else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c293d-d686-4519-a87b-77a2af652d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# print(pred_dict)\n",
    "def test_hard_samples(hard_samples, seed):\n",
    "    print(seed)\n",
    "    pred_path = \"/reef/sqt2/BERTCRAFT/cmv/roberta-base/seed-{}/predictions.csv\".format(seed)\n",
    "    pred_file = open(pred_path, 'r')\n",
    "    pred_lines = pred_file.readlines()[1:]\n",
    "    pred_dict = {}\n",
    "    for line in pred_lines:\n",
    "        id2pred = line.split(\",\")\n",
    "        \n",
    "        assert len(id2pred) == 3\n",
    "        utt_id = id2pred[0]\n",
    "        utt_pred = id2pred[1]\n",
    "        pred_dict[utt_id] = int(utt_pred)\n",
    "        \n",
    "    for convo in corpus.iter_conversations():\n",
    "        # only consider test set conversations (we did not make predictions for the other ones)\n",
    "        if convo.id in hard_samples:\n",
    "            for utt in convo.iter_utterances():\n",
    "                if utt.id in pred_dict:\n",
    "                    utt.meta['forecast_score'] = pred_dict[utt.id]\n",
    "    \n",
    "    conversational_forecasts_df = {\n",
    "            \"convo_id\": [],\n",
    "            \"label\": [],\n",
    "            \"prediction\": []\n",
    "        }\n",
    "    for convo in corpus.iter_conversations():\n",
    "        if convo.id in hard_samples:\n",
    "            conversational_forecasts_df['convo_id'].append(convo.id)\n",
    "            conversational_forecasts_df['label'].append(int(convo.meta[label_metadata]))\n",
    "            forecast_scores = [utt.meta['forecast_score'] for utt in convo.iter_utterances() if 'forecast_score' in utt.meta]\n",
    "            conversational_forecasts_df['prediction'].append(max(forecast_scores))\n",
    "    conversational_forecasts_df = pd.DataFrame(conversational_forecasts_df).set_index(\"convo_id\")\n",
    "    test_labels = conversational_forecasts_df.label\n",
    "    test_preds = conversational_forecasts_df.prediction\n",
    "    test_acc = (test_labels == test_preds).mean()\n",
    "    \n",
    "    \n",
    "    tp = ((test_labels==1)&(test_preds==1)).sum()\n",
    "    fp = ((test_labels==0)&(test_preds==1)).sum()\n",
    "    tn = ((test_labels==0)&(test_preds==0)).sum()\n",
    "    fn = ((test_labels==1)&(test_preds==0)).sum()\n",
    "\n",
    "    test_precision = tp / (tp + fp)\n",
    "    test_recall = tp / (tp + fn)\n",
    "    test_fpr = fp / (fp + tn)\n",
    "    test_f1 = 2 / (((tp + fp) / tp) + ((tp + fn) / tp))\n",
    "    \n",
    "    print(\"\\tAccuracy:\", test_acc)\n",
    "    print(\"\\tPrecision:\", test_precision)\n",
    "    print(\"\\tRecall:\", test_recall)\n",
    "    print(\"\\tF1:\", test_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b8720-d9d1-4f44-ad2f-198c58927dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1,11):\n",
    "    test_hard_samples(hard_samples, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9ead1-b6e4-49f1-9858-0854f72d8611",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "for convo in corpus.iter_conversations():\n",
    "    if convo.meta['split'] == 'test':\n",
    "        test_samples.append(convo.id)\n",
    "for seed in range(1,11):\n",
    "    test_hard_samples(test_samples, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11f718-5037-41ec-9240-3b35de3b8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "(max([0,1,0,0,0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c046c-32fc-4fd6-91d8-33eeeb784cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jacq-zissou-env-3.11",
   "language": "python",
   "name": "jacq-zissou-env-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
