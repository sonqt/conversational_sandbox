{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Users/tran_s2/.local/lib/python3.11/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Volumes/Users/tran_s2/.convokit/downloads/conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "# from transformers import RobertaModel\n",
    "\n",
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"DeepPavlov/bert-base-cased-conversational\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPairs(corpus, split=None, last_only=False):\n",
    "    \"\"\"\n",
    "    Load context-reply pairs from the Corpus, optionally filtering to only conversations\n",
    "    from the specified split (train, val, or test).\n",
    "    Each conversation, which has N comments (not including the section header) will\n",
    "    get converted into N-1 comment-reply pairs, one pair for each reply\n",
    "    (the first comment does not reply to anything).\n",
    "    Each comment-reply pair is a tuple consisting of the conversational context\n",
    "    (that is, all comments prior to the reply), the reply itself, the label (that\n",
    "    is, whether the reply contained a derailment event), and the comment ID of the\n",
    "    reply (for later use in re-joining with the ConvoKit corpus).\n",
    "    The function returns a list of such pairs.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    count_attack = 0\n",
    "    count_convo = 0\n",
    "    for convo in corpus.iter_conversations():\n",
    "        # consider only conversations in the specified split of the data\n",
    "        if split is None or convo.meta['split'] == split:\n",
    "            count_convo += 1\n",
    "            utterance_list = []\n",
    "            for utterance in convo.iter_utterances():\n",
    "                if utterance.meta['is_section_header']:\n",
    "                    continue\n",
    "                if utterance.meta['comment_has_personal_attack']:\n",
    "                    count_attack += 1\n",
    "                utterance_list.append({\"text\": utterance.text, \n",
    "                                        \"is_attack\": int(utterance.meta['comment_has_personal_attack']), \n",
    "                                        \"id\": utterance.id})\n",
    "                \n",
    "            iter_range = range(1, len(utterance_list)) if not last_only else [len(utterance_list)-1]\n",
    "            for idx in iter_range:\n",
    "                reply = utterance_list[idx][\"text\"]\n",
    "                label = utterance_list[idx][\"is_attack\"]\n",
    "                comment_id = utterance_list[idx][\"id\"]\n",
    "                # gather as context all utterances preceding the reply\n",
    "                context = [u[\"text\"] for u in utterance_list[idx-2:idx]]\n",
    "                pairs.append((context, label))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = loadPairs(corpus, split='train', last_only=True)\n",
    "val_pairs = loadPairs(corpus, split='val', last_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2508\n",
      "840\n"
     ]
    }
   ],
   "source": [
    "print(len(train_pairs))\n",
    "print(len(val_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "count_pos = 0\n",
    "single_comment = 0\n",
    "for i in range(len(train_pairs)):\n",
    "    # assert len(train_pairs[i][0]) == 2\n",
    "    if train_pairs[i][1] == 1:\n",
    "        count_pos += 1\n",
    "print(single_comment/len(train_pairs), count_pos/len(train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "count_pos = 0\n",
    "single_comment = 0\n",
    "for i in range(len(val_pairs)):\n",
    "    if len(val_pairs[i][0]) != 2:\n",
    "        single_comment += 1\n",
    "    if val_pairs[i][1] == 1:\n",
    "        count_pos += 1\n",
    "print(single_comment/len(val_pairs), count_pos/len(val_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac70824148764548bdc17eb8ac0e2cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6b7f2fc50d4df792147ce2082b8e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d04ce530d0475ca2c34d8ca6d52a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39954a072e554f1fa32f5e467065fcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing comments...\n",
      "  Tokenized 0 comments.\n",
      "  Tokenized 500 comments.\n",
      "  Tokenized 1,000 comments.\n",
      "  Tokenized 1,500 comments.\n",
      "  Tokenized 2,000 comments.\n",
      "  Tokenized 2,500 comments.\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# By default, the tokenizer will spit out a warning whenever we tokenize a \n",
    "# sample which ends up being more than 512 tokens. We don't care about that for\n",
    "# now, though, and this cell will produce a lot of those warnings! So we'll \n",
    "# adjust the logging settings to suppress those warnings and keep the output\n",
    "# cell cleaner.\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
    "\n",
    "# Record the length of each sequence (in terms of BERT tokens).\n",
    "lengths = []\n",
    "\n",
    "print('Tokenizing comments...')\n",
    "contexts = []\n",
    "labels = []\n",
    "\n",
    "# For every sentence...\n",
    "for context, label in train_pairs:\n",
    "    # contexts.append(context)\n",
    "    # labels.append(label)\n",
    "    # Report progress.\n",
    "    if ((len(lengths) % 500) == 0):\n",
    "        print('  Tokenized {:,} comments.'.format(len(lengths)))\n",
    "    # # print(len(context))\n",
    "    # # print(*context)\n",
    "    encoded_sent = tokenizer.encode(*context)\n",
    "    # print(encoded_sent)\n",
    "\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min length: 2 tokens\n",
      "   Max length: 5,409 tokens\n",
      "Median length: 137 tokens\n"
     ]
    }
   ],
   "source": [
    "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
    "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(lengths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "# sns.set(font_scale=1.5)\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Truncate any comment lengths greater than 512.\n",
    "trunc_lengths = [min(l, 512) for l in lengths]\n",
    "\n",
    "# Plot the distribution of comment lengths.\n",
    "sns.histplot(trunc_lengths)\n",
    "\n",
    "# Alternatively, you might try using a log scale on the x-axis, but this is \n",
    "# tricky. See here for one approach:\n",
    "# https://stackoverflow.com/questions/47850202/plotting-a-histogram-on-a-log-scale-with-matplotlib?rq=1\n",
    "#plt.xscale('log')\n",
    "\n",
    "plt.title('Comment Lengths')\n",
    "plt.xlabel('Comment Length')\n",
    "plt.ylabel('# of Comments')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many comments will be truncated?\n",
      "\n",
      "max_len = 128  -->    1,331 of   2,508  (53.1%)  will be truncated \n",
      "max_len = 256  -->      534 of   2,508  (21.3%)  will be truncated \n",
      "max_len = 300  -->      406 of   2,508  (16.2%)  will be truncated \n",
      "max_len = 400  -->      215 of   2,508  ( 8.6%)  will be truncated \n",
      "max_len = 512  -->      131 of   2,508  ( 5.2%)  will be truncated \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cast the list to a numpy array so we can use some numpy features.\n",
    "lengths = np.asarray(lengths)\n",
    "\n",
    "# Get the total number of comments.\n",
    "num_comments = len(lengths)\n",
    "\n",
    "# Check the following lengths:\n",
    "max_lens = [128, 256, 300, 400, 512]\n",
    "\n",
    "print('How many comments will be truncated?\\n')\n",
    "\n",
    "# For each choice...\n",
    "for max_len in max_lens:\n",
    "\n",
    "    # Calculate how many comments will be truncacted.\n",
    "    num_over = np.sum(lengths > max_len)\n",
    "\n",
    "    # And as a percentage.\n",
    "    prcnt_over = float(num_over) / float(num_comments)\n",
    "\n",
    "    print('max_len = {:}  -->  {:>7,} of {:>7,}  ({:>5.1%})  ' \\\n",
    "          'will be truncated '.format(\n",
    "              max_len, num_over, num_comments, prcnt_over\n",
    "          ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our sequence length to pad or truncate all of our samples to.\n",
    "max_len = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "def build_dataloadder(pairs):\n",
    "    # question = \"Is this conversation likely to turn into personal attack?\"\n",
    "    input_ids = []\n",
    "    attn_masks = []\n",
    "    labels = []\n",
    "    print('Encoding {:,} training examples...'.format(len(pairs)))\n",
    "\n",
    "    # For every training example...\n",
    "    for context, label in pairs:\n",
    "\n",
    "        # Report progress.\n",
    "        if ((len(input_ids) % 500) == 0):\n",
    "            print('  Encoded {:,} comments.'.format(len(input_ids)))\n",
    "\n",
    "        # Convert sentence pairs to input IDs, with attention masks.\n",
    "        encoded_dict = tokenizer.encode_plus(*context,\n",
    "                                            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                                            max_length=max_len,    # Pad or truncate to this lenght.\n",
    "                                            pad_to_max_length=True,\n",
    "                                            truncation=True, \n",
    "                                            return_tensors='pt')   # Return objects as PyTorch tensors.\n",
    "\n",
    "        # Add this example to our lists.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attn_masks.append(encoded_dict['attention_mask'])\n",
    "        labels.append(label)\n",
    "\n",
    "    # labels = labels.astype(float)\n",
    "    # Cast the labels list to a 2D Tensor.\n",
    "    labels = torch.tensor(labels)\n",
    "    # print(labels.type())\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attn_masks = torch.cat(attn_masks, dim=0)\n",
    "    dataset = TensorDataset(input_ids, attn_masks, labels)\n",
    "    print('DONE.')\n",
    "    return DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 2,508 training examples...\n",
      "  Encoded 0 comments.\n",
      "  Encoded 500 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Users/tran_s2/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Encoded 1,000 comments.\n",
      "  Encoded 1,500 comments.\n",
      "  Encoded 2,000 comments.\n",
      "  Encoded 2,500 comments.\n",
      "DONE.\n",
      "Encoding 840 training examples...\n",
      "  Encoded 0 comments.\n",
      "  Encoded 500 comments.\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = build_dataloadder(train_pairs)\n",
    "val_dataloader = build_dataloadder(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890f999166a744bb8a61bb20b4ad268c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/bert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AdamW\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Users/tran_s2/.local/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5,\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (BERT authors recommend between 2 and 4)\n",
    "epochs = 10\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))  \n",
    "def good_update_interval(total_iters, num_desired_updates):\n",
    "    '''\n",
    "    This function will try to pick an intelligent progress update interval \n",
    "    based on the magnitude of the total iterations.\n",
    "\n",
    "    Parameters:\n",
    "      `total_iters` - The number of iterations in the for-loop.\n",
    "      `num_desired_updates` - How many times we want to see an update over the \n",
    "                              course of the for-loop.\n",
    "    '''\n",
    "    # Divide the total iterations by the desired number of updates. Most likely\n",
    "    # this will be some ugly number.\n",
    "    exact_interval = total_iters / num_desired_updates\n",
    "\n",
    "    # The `round` function has the ability to round down a number to, e.g., the\n",
    "    # nearest thousandth: round(exact_interval, -3)\n",
    "    #\n",
    "    # To determine the magnitude to round to, find the magnitude of the total,\n",
    "    # and then go one magnitude below that.\n",
    "\n",
    "    # Get the order of magnitude of the total.\n",
    "    order_of_mag = len(str(total_iters)) - 1\n",
    "\n",
    "    # Our update interval should be rounded to an order of magnitude smaller. \n",
    "    round_mag = order_of_mag - 1\n",
    "\n",
    "    # Round down and cast to an int.\n",
    "    update_interval = int(round(exact_interval, -round_mag))\n",
    "\n",
    "    # Don't allow the interval to be zero!\n",
    "    if update_interval == 0:\n",
    "        update_interval = 1\n",
    "\n",
    "    return update_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score(labels, preds):\n",
    "    # preds = torch.sigmoid(logits) > 0.5\n",
    "    # Calculating precision, recall, and F1 score using PyTorch\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    TP = ((preds == 1) & (labels == 1)).sum().item()\n",
    "    FP = ((preds == 1) & (labels == 0)).sum().item()\n",
    "    FN = ((preds == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return f1\n",
    "def calculate_accuracy_score(labels, preds):\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    return (labels == preds).sum().item()/labels.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dataloader):\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_loss = 0\n",
    "\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in val_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():   \n",
    "   \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "    # Measure validation accuracy...\n",
    "\n",
    "    # Combine the results across all batches. \n",
    "    flat_predictions = np.concatenate(predictions, axis=0)\n",
    "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "    # Calculate the validation accuracy.\n",
    "    val_f1 = calculate_f1_score(flat_true_labels, flat_predictions)\n",
    "    val_acc = calculate_accuracy_score(flat_true_labels, flat_predictions)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  F1 Score: {0:.2f}\".format(val_f1))\n",
    "    print(\"  Accuracy: {0:.2f}\".format(val_acc))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "  F1 Score: 0.01\n",
      "  Accuracy: 0.50\n",
      "  Validation Loss: 0.71\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    157.    Elapsed: 0:00:06.\n",
      "  Batch    40  of    157.    Elapsed: 0:00:11.\n",
      "  Batch    60  of    157.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    157.    Elapsed: 0:00:23.\n",
      "  Batch   100  of    157.    Elapsed: 0:00:28.\n",
      "  Batch   120  of    157.    Elapsed: 0:00:34.\n",
      "  Batch   140  of    157.    Elapsed: 0:00:40.\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  F1 Score: 0.69\n",
      "  Accuracy: 0.58\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    157.    Elapsed: 0:00:06.\n",
      "  Batch    40  of    157.    Elapsed: 0:00:12.\n",
      "  Batch    60  of    157.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    157.    Elapsed: 0:00:23.\n",
      "  Batch   100  of    157.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    157.    Elapsed: 0:00:35.\n",
      "  Batch   140  of    157.    Elapsed: 0:00:40.\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  F1 Score: 0.62\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 0.68\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    157.    Elapsed: 0:00:06.\n",
      "  Batch    40  of    157.    Elapsed: 0:00:12.\n",
      "  Batch    60  of    157.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    157.    Elapsed: 0:00:23.\n",
      "  Batch   100  of    157.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    157.    Elapsed: 0:00:35.\n",
      "  Batch   140  of    157.    Elapsed: 0:00:40.\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  F1 Score: 0.60\n",
      "  Accuracy: 0.63\n",
      "  Validation Loss: 0.88\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    157.    Elapsed: 0:00:06.\n",
      "  Batch    40  of    157.    Elapsed: 0:00:12.\n",
      "  Batch    60  of    157.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    157.    Elapsed: 0:00:23.\n",
      "  Batch   100  of    157.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    157.    Elapsed: 0:00:35.\n",
      "  Batch   140  of    157.    Elapsed: 0:00:40.\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  F1 Score: 0.65\n",
      "  Accuracy: 0.64\n",
      "  Validation Loss: 1.14\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    157.    Elapsed: 0:00:06.\n",
      "  Batch    40  of    157.    Elapsed: 0:00:12.\n",
      "  Batch    60  of    157.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    157.    Elapsed: 0:00:23.\n",
      "  Batch   100  of    157.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    157.    Elapsed: 0:00:35.\n",
      "  Batch   140  of    157.    Elapsed: 0:00:40.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  F1 Score: 0.61\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 1.81\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    20  of    157.    Elapsed: 0:00:06.\n",
      "  Batch    40  of    157.    Elapsed: 0:00:12.\n",
      "  Batch    60  of    157.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    157.    Elapsed: 0:00:23.\n",
      "  Batch   100  of    157.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    157.    Elapsed: 0:00:35.\n",
      "  Batch   140  of    157.    Elapsed: 0:00:40.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    evaluate(model, val_dataloader)\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # Pick an interval on which to print progress updates.\n",
    "    update_interval = good_update_interval(\n",
    "                total_iters = len(train_dataloader), \n",
    "                num_desired_updates = 10\n",
    "            )\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update.\n",
    "        if (step % update_interval) == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This call returns the loss (because we provided labels) and the \n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    " \n",
    "    \n",
    "\n",
    "    # # Record all statistics from this epoch.\n",
    "    # training_stats.append(\n",
    "    #     {\n",
    "    #         'epoch': epoch_i + 1,\n",
    "    #         'Training Loss': avg_train_loss,\n",
    "    #         'Valid. Loss': avg_val_loss,\n",
    "    #         'Valid. Accur.': val_acc,\n",
    "    #         'Training Time': training_time,\n",
    "    #         'Validation Time': validation_time\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
